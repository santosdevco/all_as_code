# ğŸ“ Decisiones ArquitectÃ³nicas (ADRs)

## ğŸ¯ Objetivo

Documentar decisiones arquitectÃ³nicas importantes del sistema WhatHelp Chat API, incluyendo contexto, alternativas evaluadas, razones de elecciÃ³n y consecuencias (trade-offs) aceptadas.

---

## ğŸ“‹ Ãndice de Decisiones

| ID | DecisiÃ³n | Estado | Fecha | Impacto |
|----|----------|--------|-------|---------|
| ADR-001 | Usar PostgreSQL como base de datos principal | Aceptada | Heredado (pre-2024) | Alto |
| ADR-002 | Integrar IBM Watson Assistant como chatbot | Aceptada | Heredado (pre-2024) | Alto |
| ADR-003 | Arquitectura de monolito en vez de microservicios | Aceptada | Heredado (pre-2024) | Alto |
| ADR-004 | Usar IBM Cloud Object Storage para archivos | Aceptada | Heredado (pre-2024) | Medio |
| ADR-005 | Implementar cache Redis con fallback a DB | Aceptada | 2024 | Medio |
| ADR-006 | Usar Socket.IO sin Redis Adapter (temporal) | En revisiÃ³n | 2024 | Alto |
| ADR-007 | Cron jobs en monolito con flags de control | Obsoleta | Heredado â†’ Q1 2026 | Alto |
| ADR-008 | No usar TypeScript (JavaScript puro) | Aceptada | Heredado (pre-2024) | Medio |
| ADR-009 | PM2 como orquestador (deprecado) | Obsoleta | Heredado â†’ Q1 2026 | Bajo |
| ADR-010 | Cache TTL: Watson 1h, Usuarios 15min, Salas 5min | Aceptada | 2024 | Bajo |
| ADR-011 | Axede como proveedor WhatsApp Business API | Aceptada | Heredado (pre-2024) | Alto |
| ADR-012 | Dividir backend en 2 servicios (API vs Cron) | Planificada | Q1 2026 | Alto |

---

## ADR-001: Usar PostgreSQL como Base de Datos Principal

### Estado
**Aceptada** (Heredado de desarrollo anterior)

### Contexto

El sistema necesitaba una base de datos relacional para almacenar:

- Conversaciones con historial completo y bÃºsquedas complejas

- Relaciones entre entidades (agentes, usuarios, salas, mensajes)

- Transacciones ACID para operaciones crÃ­ticas (asignaciÃ³n de conversaciones, transferencias)

- Reportes y mÃ©tricas agregadas

**Restricciones:**

- Proyecto heredado de un desarrollo anterior de propÃ³sito general

- Equipo con experiencia en SQL

### DecisiÃ³n

Usar **PostgreSQL** como base de datos principal del sistema.

**RazÃ³n oficial (del formulario):** *"AplicaciÃ³n heredada de un desarrollo anterior de propÃ³sito general"*

### Alternativas Consideradas

1. **MongoDB (NoSQL)**
   - **Pros:** Esquema flexible, buena performance para writes masivos, escalado horizontal nativo
   - **Contras:** Sin transacciones ACID multi-documento (en versiones antiguas), queries complejos menos eficientes, equipo sin experiencia
   - **Por quÃ© se rechazÃ³:** Necesidad de transacciones y joins complejos

2. **MySQL**
   - **Pros:** Similar a PostgreSQL, gran comunidad, hosting barato
   - **Contras:** Menor soporte para JSON, full-text search menos potente, menor extensibilidad
   - **Por quÃ© se rechazÃ³:** PostgreSQL tiene mejores features para el caso de uso

3. **Microsoft SQL Server**
   - **Pros:** IntegraciÃ³n nativa con Azure/IBM Cloud, herramientas enterprise
   - **Contras:** Costos de licenciamiento, vendor lock-in
   - **Por quÃ© se rechazÃ³:** Costos y complejidad innecesaria

### Consecuencias

**Positivas:**

- âœ… Transacciones ACID garantizan consistencia en operaciones crÃ­ticas

- âœ… Ãndices optimizados mejoran performance de queries (50-150ms ganados)

- âœ… Full-text search nativo para bÃºsquedas en mensajes

- âœ… Soporte JSON para datos semi-estructurados (metadata de mensajes)

- âœ… Extensibilidad con pgcrypto, pg_trgm, etc.

- âœ… Equipo familiarizado con SQL

**Negativas (Trade-offs aceptados):**

- âŒ Escalado horizontal complejo (requiere sharding manual o Citus)

- âŒ Performance de writes menor que NoSQL (aceptable para 1-1,000 msg/dÃ­a)

- âŒ Schema rÃ­gido dificulta cambios rÃ¡pidos de modelo

**Riesgos y mitigaciones:**

- **Riesgo:** Queries lentos en tablas grandes
  - **MitigaciÃ³n:** 8 Ã­ndices estratÃ©gicos aplicados (ver db/migrations/)

- **Riesgo:** Deadlocks en alta concurrencia
  - **MitigaciÃ³n:** Timeouts configurados, retry logic en queries crÃ­ticas

### MÃ©tricas Actuales

- **Pool de conexiones:** max: 20, min: 5

- **Queries optimizadas:** 50-150ms de mejora con Ã­ndices

- **Tablas principales:** 36 tablas (rooms, messages, agents, queues, etc.)

### Referencias

- ConfiguraciÃ³n pool: `app/services/postgresql.js`

- Ãndices aplicados: `db/migrations/*.sql`

- Optimizaciones: `OPTIMIZACIONES_ADICIONALES.md`

---

## ADR-002: Integrar IBM Watson Assistant como Chatbot

### Estado
**Aceptada** (En evaluaciÃ³n de migraciÃ³n futura)

### Contexto

El sistema requerÃ­a un asistente virtual para:

- Atender primera lÃ­nea de soporte (reducir carga de agentes humanos)

- Capturar informaciÃ³n inicial de usuarios (nombre, tipo de consulta, etc.)

- Resolver consultas frecuentes automÃ¡ticamente

- Detectar intenciones y enrutar a Ã¡rea correcta

- Procesar lenguaje natural en espaÃ±ol

**Restricciones:**

- AplicaciÃ³n nativa de IBM Cloud

- Posible requisito contractual con IBM

### DecisiÃ³n

Usar **IBM Watson Assistant v10.0.0** como motor de chatbot.

**RazÃ³n oficial (del formulario):** *"AplicaciÃ³n nativa de IBM Cloud"*

### Alternativas Consideradas

1. **Google Dialogflow**
   - **Pros:** Excelente NLU, integraciÃ³n con Google Cloud, pricing competitivo
   - **Contras:** Vendor lock-in a Google, migraciÃ³n compleja desde IBM Cloud
   - **Por quÃ© se rechazÃ³:** No alineado con ecosistema IBM Cloud del cliente

2. **Rasa Open Source**
   - **Pros:** Self-hosted, sin costos de API, control total, customizable
   - **Contras:** Requiere expertise en ML/NLP, mantenimiento complejo, hosting adicional
   - **Por quÃ© se rechazÃ³:** Equipo sin experiencia en ML, overhead operacional

3. **Twilio Autopilot**
   - **Pros:** IntegraciÃ³n nativa con Twilio WhatsApp, fÃ¡cil setup
   - **Contras:** Menos potente en NLU que Watson/Dialogflow, vendor lock-in
   - **Por quÃ© se rechazÃ³:** Cliente ya tenÃ­a contrato IBM

4. **Microsoft Bot Framework + LUIS**
   - **Pros:** IntegraciÃ³n con Teams (ya usado), Azure ecosystem
   - **Contras:** Ecosistema diferente a IBM Cloud
   - **Por quÃ© se rechazÃ³:** No alineado con IBM Cloud

### Consecuencias

**Positivas:**

- âœ… NLU potente para espaÃ±ol (entrenado por IBM)

- âœ… IntegraciÃ³n nativa con IBM Cloud (mismo proveedor que hosting)

- âœ… SDK oficial de Node.js bien documentado

- âœ… Capacidades de diÃ¡logo multi-turn (contexto de conversaciÃ³n)

- âœ… IntegraciÃ³n con Watson Discovery (futuro)

**Negativas (Trade-offs aceptados):**

- âŒ Vendor lock-in a IBM Watson

- âŒ Costos por API call (pricing basado en uso)

- âŒ Latencia adicional en cada mensaje (mitigado con cache de sesiones)

- âŒ Dependencia de servicio externo (si Watson falla, solo queda modo humano)

**Riesgos y mitigaciones:**

- **Riesgo:** Watson Assistant no disponible
  - **MitigaciÃ³n:** Try-catch en cÃ³digo, fallback a agente humano directo

- **Riesgo:** Latencia alta en Watson API
  - **MitigaciÃ³n:** Cache de session IDs (TTL: 1h, mejora 80-200ms)

- **Riesgo:** Costos escalados con alto volumen
  - **MitigaciÃ³n:** Monitorear usage, evaluar alternativas si volumen crece 10x

### Estado Actual

**En evaluaciÃ³n de migraciÃ³n:** SegÃºn respuesta del formulario (`watson_migration_plans: evaluating`), se estÃ¡ considerando migrar a otra plataforma en el futuro.

**Posibles razones:**

- Costos acumulados

- Limitaciones de Watson Assistant

- Alternativas mÃ¡s potentes (GPT-4, Claude, Gemini con function calling)

### MÃ©tricas Actuales

- **Cache de sesiones:** TTL 1h, reducciÃ³n 80-200ms latencia

- **SLA esperado:** No especificado en respuestas (campo vacÃ­o)

- **Failover:** BÃ¡sico (try-catch, sin circuit breaker)

### Referencias

- IntegraciÃ³n: `app/logic/AssistantLogic.js`

- Service wrapper: `app/services/watson/assistant.js`

- Cache: `app/logic/WatsonSessionId.js`

- OptimizaciÃ³n: `CACHE_IMPLEMENTATION.md`

---

## ADR-003: Arquitectura de Monolito en vez de Microservicios

### Estado
**Aceptada** (Con plan de evoluciÃ³n a 2 servicios en Q1 2026)

### Contexto

El sistema necesitaba ser desarrollado rÃ¡pidamente con equipo pequeÃ±o, priorizando:

- Time-to-market rÃ¡pido

- Simplicidad de despliegue

- Bajo overhead operacional

- Equipo pequeÃ±o sin experiencia en microservicios

**Restricciones:**

- AplicaciÃ³n heredada con esta arquitectura

- Volumen bajo (1-1,000 mensajes/dÃ­a)

- 1 instancia en producciÃ³n suficiente

### DecisiÃ³n

Usar **arquitectura de monolito modular** con todos los componentes en un Ãºnico proceso Node.js.

**RazÃ³n oficial (del formulario):** *"AplicaciÃ³n heredada con esta arquitectura"*

**Trade-off aceptado (del formulario):** *"Monolito para gestiÃ³n de cambios"*

### Alternativas Consideradas

1. **Microservicios (WhatsApp Service + Watson Service + API Service + Cron Service)**
   - **Pros:** Escalado independiente, deployments independientes, fault isolation
   - **Contras:** Complejidad operacional 10x, overhead de red, consistencia distribuida, equipo pequeÃ±o
   - **Por quÃ© se rechazÃ³:** Overhead innecesario para el volumen actual, equipo pequeÃ±o

2. **Serverless (AWS Lambda / IBM Cloud Functions)**
   - **Pros:** Auto-scaling, pay-per-use, sin gestiÃ³n de infraestructura
   - **Contras:** Cold starts, lÃ­mites de ejecuciÃ³n, stateless (problemÃ¡tico para WebSockets), debugging complejo
   - **Por quÃ© se rechazÃ³:** WebSockets difÃ­ciles de implementar, vendor lock-in extremo

3. **Modular Monolith con Domain Boundaries**
   - **Pros:** Balance entre simplicidad y modularidad, evoluciÃ³n futura a microservicios
   - **Contras:** Requiere disciplina en boundaries, puede acumular deuda tÃ©cnica
   - **Por quÃ© se aceptÃ³ (variante elegida):** Se implementÃ³ separaciÃ³n en capas (Controllers, Logic, Services)

### Consecuencias

**Positivas:**

- âœ… Despliegue simple (un Ãºnico Dockerfile)

- âœ… Debugging mÃ¡s fÃ¡cil (un solo proceso, un solo log)

- âœ… No hay overhead de red entre componentes

- âœ… Transacciones simples (todo en un DB, sin distributed transactions)

- âœ… Menor complejidad operacional (1 proceso vs 5+ servicios)

- âœ… Desarrollo rÃ¡pido (cambios no requieren coordinar mÃºltiples repos)

**Negativas (Trade-offs aceptados):**

- âŒ No se pueden escalar componentes independientemente (ej: solo cron jobs)

- âŒ Fallo de un componente tumba todo el sistema

- âŒ Deployments all-or-nothing (riesgo mayor)

- âŒ Dificultad para equipos grandes (merge conflicts en mono-repo)

- âŒ LÃ­mites de escalado vertical (CPU/RAM de una mÃ¡quina)

**Riesgos y mitigaciones:**

- **Riesgo:** Cron jobs generan race conditions con mÃºltiples instancias
  - **MitigaciÃ³n:** Flags en DB (temporal), **Q1 2026: Dividir en 2 servicios**

- **Riesgo:** Socket.IO sin Redis Adapter impide escalado horizontal
  - **MitigaciÃ³n:** **Q1 2026: Implementar Redis Adapter**

- **Riesgo:** Deuda tÃ©cnica acumulada (ej: Room.js con 750 lÃ­neas)
  - **MitigaciÃ³n:** RefactorizaciÃ³n planificada (ver ADR-012)

### EvoluciÃ³n Planificada (Q1 2026)

**DivisiÃ³n en 2 servicios:**

1. **Servicio API + WebSockets (mÃºltiples instancias)**
   - Controllers + Logic + Services
   - Socket.IO con Redis Adapter
   - Escalado horizontal completo

2. **Servicio Cron Jobs (instancia Ãºnica)**
   - queue.js, rooms.js, room_files.js, report.js
   - Sin escalado (no necesario)
   - Elimina race conditions

**Futuro (Fase 2):** MigraciÃ³n a Kafka con IBM para event-driven architecture

### Referencias

- Respuesta formulario: `why_monolith: "AplicaciÃ³n heredada con esta arquitectura"`

- Plan divisiÃ³n: Respuesta `cron_solution`

- Problemas detectados: Respuesta `problematic_component`

---

## ADR-004: Usar IBM Cloud Object Storage para Archivos

### Estado
**Aceptada**

### Contexto

El sistema necesitaba almacenar archivos adjuntos enviados por usuarios y agentes:

- ImÃ¡genes (capturas de pantalla, fotos)

- Documentos (PDFs, Word, Excel)

- Audios (notas de voz)

- Archivos temporales de reportes

**Restricciones:**

- AplicaciÃ³n nativa de IBM Cloud

- Almacenamiento en filesystem local no escalable

### DecisiÃ³n

Usar **IBM Cloud Object Storage (COS)** con SDK v1.14.1 (S3-compatible).

**RazÃ³n oficial (del formulario):** *"AplicaciÃ³n nativa de IBM Cloud"*

### Alternativas Consideradas

1. **AWS S3**
   - **Pros:** LÃ­der del mercado, pricing competitivo, mejor ecosistema, multi-regiÃ³n
   - **Contras:** Vendor diferente a IBM Cloud (donde estÃ¡ la app), costos de egress entre clouds
   - **Por quÃ© se rechazÃ³:** Cliente quiere todo en IBM Cloud

2. **Azure Blob Storage**
   - **Pros:** IntegraciÃ³n con Teams (ya usado), pricing similar a S3
   - **Contras:** Vendor diferente, complejidad multi-cloud
   - **Por quÃ© se rechazÃ³:** No alineado con IBM Cloud

3. **Filesystem Local (servidor)**
   - **Pros:** Gratis, simple, sin latencia de red
   - **Contras:** No escalable, backups manuales, pÃ©rdida de datos si server falla
   - **Por quÃ© se rechazÃ³:** No es production-ready

4. **PostgreSQL (BYTEA o Large Objects)**
   - **Pros:** Todo en un solo lugar, transaccional
   - **Contras:** Performance horrible para archivos grandes, backups pesados, no recomendado
   - **Por quÃ© se rechazÃ³:** AntipatrÃ³n conocido

### Consecuencias

**Positivas:**

- âœ… Almacenamiento ilimitado (pay-per-use)

- âœ… Durabilidad 99.999999999% (11 nines)

- âœ… API S3-compatible (fÃ¡cil migrar a otro proveedor si necesario)

- âœ… CDN integrado para servir archivos rÃ¡pido

- âœ… Lifecycle policies para eliminaciÃ³n automÃ¡tica

**Negativas (Trade-offs aceptados):**

- âŒ Vendor lock-in a IBM Cloud

- âŒ Costos por GB almacenado + requests

- âŒ Latencia adicional vs filesystem local (aceptable)

- âŒ Dependencia de servicio externo (si COS falla, no se pueden enviar archivos)

**Riesgos y mitigaciones:**

- **Riesgo:** IBM COS no disponible
  - **MitigaciÃ³n:** Try-catch en cÃ³digo, mensajes de texto siguen funcionando

- **Riesgo:** Costos escalados con alto volumen de archivos
  - **MitigaciÃ³n:** Cron job de limpieza (room_files.js, ejecuta 23:30 diario)

### MÃ©tricas Actuales

- **Limpieza automÃ¡tica:** 23:30 diario (archivos antiguos)

- **RetenciÃ³n:** No especificado en respuestas

### Referencias

- Service wrapper: `app/services/storage.js`

- Cron limpieza: `app/cron/room_files.js`

---

## ADR-005: Implementar Cache Redis con Fallback AutomÃ¡tico

### Estado
**Aceptada** (Solo en desarrollo, producciÃ³n en Q1 2026)

### Contexto

El sistema tenÃ­a problemas de performance:

- Queries repetitivas a PostgreSQL (session IDs de Watson, datos de usuarios)

- Latencia 80-200ms en cada request a Watson API

- Volumen creciente de mensajes degradaba performance

**Objetivo:** Reducir latencia 15-35% sin romper la aplicaciÃ³n si cache falla.

### DecisiÃ³n

Implementar **Redis 4.6.0** como capa de cache con **fallback automÃ¡tico a PostgreSQL** si Redis no estÃ¡ disponible.

### Alternativas Consideradas

1. **Memcached**
   - **Pros:** MÃ¡s simple que Redis, menor footprint de memoria
   - **Contras:** Sin persistencia, sin estructuras de datos avanzadas, sin pub/sub (necesario para Socket.IO adapter futuro)
   - **Por quÃ© se rechazÃ³:** Redis mÃ¡s versÃ¡til para necesidades futuras

2. **Cache en memoria (Node.js)**
   - **Pros:** Zero latency, sin dependencias externas
   - **Contras:** Memoria limitada del proceso Node.js, no compartido entre instancias, se pierde al reiniciar
   - **Por quÃ© se rechazÃ³:** No escalable a mÃºltiples instancias

3. **No usar cache (solo PostgreSQL)**
   - **Pros:** Simplicidad, un componente menos
   - **Contras:** Performance degradada (80-200ms mÃ¡s lento)
   - **Por quÃ© se rechazÃ³:** Latencia inaceptable

### Consecuencias

**Positivas:**

- âœ… **Mejora de performance: 80-200ms (15-35%)** segÃºn CACHE_IMPLEMENTATION.md

- âœ… Fallback automÃ¡tico: si Redis falla, consulta PostgreSQL (resiliente)

- âœ… No rompe la aplicaciÃ³n si Redis no estÃ¡ disponible

- âœ… PreparaciÃ³n para Socket.IO Redis Adapter (Q1 2026)

- âœ… Reduce carga en PostgreSQL (menos queries)

**Negativas (Trade-offs aceptados):**

- âŒ Eventual consistency: datos en cache pueden estar desactualizados (TTL configurable)

- âŒ Componente adicional para mantener (Redis server)

- âŒ Uso de memoria adicional

- âŒ Complejidad en invalidaciÃ³n de cache

**Riesgos y mitigaciones:**

- **Riesgo:** Cache stale (datos desactualizados)
  - **MitigaciÃ³n:** TTLs ajustados (Watson: 1h, Usuarios: 15min, Salas: 5min)

- **Riesgo:** Redis falla y degrada performance
  - **MitigaciÃ³n:** Fallback automÃ¡tico a DB (cÃ³digo continÃºa funcionando)

- **Riesgo:** Cache stampede (mÃºltiples requests regeneran cache simultÃ¡neamente)
  - **MitigaciÃ³n:** Implementado en cÃ³digo (verificar cache.js)

### ConfiguraciÃ³n de TTLs (ver ADR-010)

| Tipo de Dato | TTL | JustificaciÃ³n |
|--------------|-----|---------------|
| Watson Session IDs | 1 hora | Sesiones estables durante conversaciÃ³n |
| Usuarios | 15 minutos | Datos cambian poco |
| Salas Activas | 5 minutos | Datos muy dinÃ¡micos |

### Estado Actual

- âœ… **Desarrollo:** Implementado y funcionando

- âŒ **ProducciÃ³n:** AÃºn no desplegado

- ğŸ“… **Plan:** IntegraciÃ³n en Q1 2026

**RazÃ³n del delay (del formulario):** *"Se estÃ¡ implementando, saldrÃ¡ en el Q1 2026"*

### MÃ©tricas

- **Mejora esperada:** 80-200ms (15-35%)

- **Hit rate esperado:** >80% en Watson sessions (inferido)

### Referencias

- ImplementaciÃ³n: `app/services/cache.js` (257 lÃ­neas)

- DocumentaciÃ³n: `CACHE_IMPLEMENTATION.md`

- Uso: `app/logic/WatsonSessionId.js`, `app/logic/Agent.js`, etc.

---

## ADR-006: Usar Socket.IO sin Redis Adapter (Temporal)

### Estado
**En revisiÃ³n** â†’ **SerÃ¡ resuelto en Q1 2026**

### Contexto

El sistema necesitaba comunicaciÃ³n en tiempo real entre agentes y backend:

- Notificaciones de nuevas conversaciones

- Mensajes en tiempo real

- Actualizaciones de estado de conversaciones

- Indicadores de "agente escribiendo"

**RestricciÃ³n actual:** Solo 1 instancia en producciÃ³n, pero se planea escalar horizontalmente.

### DecisiÃ³n (Temporal)

Usar **Socket.IO 4.5.2 SIN Redis Adapter** en la configuraciÃ³n actual.

**RazÃ³n:** Con 1 instancia, Redis Adapter no es necesario (todas las conexiones estÃ¡n en el mismo proceso).

### Problema Identificado

**Del formulario (`problematic_component`):**
> *"ConfiguraciÃ³n de sockets sin adapter (redis), cron jobs en monolito (al escalar horizontal hay condiciÃ³n de carrera)"*

**Impacto:**

- âŒ No se puede escalar horizontalmente (mÃºltiples instancias)

- âŒ Si se despliegan 2+ instancias:
  - Agente conectado a Instancia A no recibe eventos de Instancia B
  - Mensajes se pierden entre instancias
  - Experiencia de usuario rota

### Alternativas Consideradas

1. **Socket.IO con Redis Adapter (planificado Q1 2026)**
   - **Pros:** Eventos compartidos entre instancias, escalado horizontal completo
   - **Contras:** Requiere Redis en producciÃ³n (aÃºn no desplegado)
   - **Estado:** **Planificado para Q1 2026**

2. **WebSockets nativos + Redis Pub/Sub**
   - **Pros:** Sin dependencia de Socket.IO, mÃ¡s control
   - **Contras:** MÃ¡s cÃ³digo custom, sin auto-reconnect ni rooms de Socket.IO
   - **Por quÃ© se rechazÃ³:** Reescritura completa, no justificado

3. **Server-Sent Events (SSE)**
   - **Pros:** Unidireccional server â†’ client suficiente para notificaciones
   - **Contras:** No bidireccional, sin binary support
   - **Por quÃ© se rechazÃ³:** Necesidad de comunicaciÃ³n bidireccional

4. **GraphQL Subscriptions**
   - **Pros:** Moderno, tipado, integrado con GraphQL (si se usa)
   - **Contras:** No se usa GraphQL en el proyecto, overhead innecesario
   - **Por quÃ© se rechazÃ³:** No alineado con stack actual

### Consecuencias Actuales

**Positivas (con 1 instancia):**

- âœ… Funciona correctamente con 1 instancia

- âœ… Simple, sin componentes adicionales

- âœ… Latencia baja (todo en mismo proceso)

**Negativas (al escalar):**

- âŒ **Bloqueador crÃ­tico para escalado horizontal**

- âŒ Eventos no se propagan entre instancias

- âŒ Experiencia de usuario degradada con mÃºltiples instancias

### Plan de ResoluciÃ³n (Q1 2026)

**Del formulario (`socket_adapter_timeline`):** *"Q1 2026"*

**Pasos:**

1. Desplegar Redis en producciÃ³n

2. Implementar Socket.IO Redis Adapter

3. Configurar adapter en `app/app.js`:
   ```javascript
   const { createAdapter } = require('@socket.io/redis-adapter');
   const { createClient } = require('redis');
   
   const pubClient = createClient({ url: process.env.REDIS_URL });
   const subClient = pubClient.duplicate();
   
   io.adapter(createAdapter(pubClient, subClient));
   ```

4. Testing con mÃºltiples instancias

5. Deploy gradual (canary deployment)

### Referencias

- ConfiguraciÃ³n actual: `app/app.js` (Socket.IO sin adapter)

- LÃ³gica de eventos: `app/logic/Socket.js`

- Plan: Respuesta formulario `socket_adapter_timeline: q1-2026`

---

## ADR-007: Cron Jobs en Monolito con Flags de Control

### Estado
**Obsoleta** â†’ **SerÃ¡ reemplazada en Q1 2026**

### Contexto

El sistema necesitaba tareas programadas:

- Asignar conversaciones en cola cada 30s

- Cerrar salas inactivas automÃ¡ticamente

- Limpiar archivos antiguos (23:30 diario)

- Generar reportes (23:45 diario)

**RestricciÃ³n inicial:** Monolito con 1 instancia, cron jobs ejecutÃ¡ndose en el mismo proceso.

### DecisiÃ³n (Temporal)

Implementar **cron jobs dentro del monolito** con **flags de control en PostgreSQL** para evitar ejecuciÃ³n duplicada.

**Mecanismo:**

- Tabla `general_configurations` con flags `IN_PROGRESS` / `FINALIZED`

- Antes de ejecutar, verificar flag

- Si `IN_PROGRESS`, skip (otra instancia ejecutando)

- Si `FINALIZED`, cambiar a `IN_PROGRESS`, ejecutar, cambiar a `FINALIZED`

### Problema Identificado

**Del formulario (`problematic_component`):**
> *"Cron jobs en monolito (al escalar horizontal hay condiciÃ³n de carrera)"*

**Impacto:**

- âš ï¸ Flags en DB no son 100% confiables (race condition entre SELECT y UPDATE)

- âš ï¸ Posible ejecuciÃ³n duplicada si 2 instancias leen flag simultÃ¡neamente

- âš ï¸ Posible deadlock en high concurrency

**Ejemplo de race condition:**
```
T0: Instancia A lee flag = FINALIZED
T1: Instancia B lee flag = FINALIZED (antes de que A actualice)
T2: Instancia A actualiza flag = IN_PROGRESS, ejecuta tarea
T3: Instancia B actualiza flag = IN_PROGRESS, ejecuta tarea (duplicado!)
```

### Alternativas Consideradas

1. **Cron jobs en servicio separado (planificado Q1 2026)**
   - **Pros:** Solo 1 instancia del servicio cron, cero race conditions
   - **Contras:** Requiere divisiÃ³n de backend (2 servicios)
   - **Estado:** **Planificado para Q1 2026**

2. **Redis Distributed Lock (RedLock)**
   - **Pros:** Lock atÃ³mico, previene race conditions 100%
   - **Contras:** Requiere Redis en producciÃ³n (aÃºn no desplegado)
   - **Por quÃ© se rechazÃ³ temporalmente:** Redis aÃºn no en producciÃ³n

3. **PostgreSQL Advisory Locks**
   - **Pros:** Locks nativos de PostgreSQL, sin componentes adicionales
   - **Contras:** Pueden generar deadlocks, requiere gestiÃ³n cuidadosa
   - **Por quÃ© se rechazÃ³:** Complejidad similar a flags, mismo problema de race conditions

4. **External Cron Service (AWS EventBridge, IBM Cloud Functions)**
   - **Pros:** Serverless, sin gestiÃ³n de infraestructura, cron scheduling nativo
   - **Contras:** Vendor lock-in, costos adicionales, invocaciones HTTP tienen latencia
   - **Por quÃ© se rechazÃ³:** Overhead innecesario, preferible servicio interno

### Consecuencias Actuales

**Positivas (con 1 instancia):**

- âœ… Funciona correctamente con 1 instancia

- âœ… Simple, todo en un proceso

- âœ… No requiere componentes adicionales

**Negativas (al escalar):**

- âŒ Race condition potencial con mÃºltiples instancias

- âŒ Posible ejecuciÃ³n duplicada de tareas

- âŒ **Bloqueador para escalado horizontal**

### Plan de ResoluciÃ³n (Q1 2026)

**Del formulario (`cron_solution`):**
> *"Se dividirÃ¡ el back en dos servicios dejando los crons job en un servicio que solo tendrÃ¡ una instancia, mÃ¡s adelante se migrarÃ¡ a Kafka con IBM, eso estÃ¡ para una segunda fase en el mismo Q1 2026"*

**Arquitectura futura:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Servicio 1: API + WebSocketsâ”‚
â”‚ - Controllers               â”‚
â”‚ - Logic                     â”‚
â”‚ - Services                  â”‚
â”‚ - Socket.IO (Redis Adapter) â”‚
â”‚ â†’ MÃºltiples instancias      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Servicio 2: Cron Jobs       â”‚
â”‚ - queue.js (cada 30s)       â”‚
â”‚ - rooms.js (horarios)       â”‚
â”‚ - room_files.js (23:30)     â”‚
â”‚ - report.js (23:45)         â”‚
â”‚ â†’ Instancia ÃšNICA           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fase 2:** MigraciÃ³n a **Kafka con IBM** para event-driven architecture.

### Referencias

- Cron jobs: `app/cron/*.js`

- Flags control: Tabla `general_configurations`

- Plan: Respuesta formulario `cron_solution`

---

## ADR-008: No Usar TypeScript (JavaScript Puro)

### Estado
**Aceptada** (Heredado, sin planes de migraciÃ³n)

### Contexto

El proyecto fue desarrollado originalmente en JavaScript puro sin TypeScript.

### DecisiÃ³n

Mantener **JavaScript puro (sin TypeScript)** en todo el codebase.

**RazÃ³n oficial (del formulario):** *"AplicaciÃ³n heredada con esas caracterÃ­sticas"*

### Alternativas Consideradas

1. **Migrar a TypeScript**
   - **Pros:** Type safety, mejor autocompletado IDE, refactoring mÃ¡s seguro, menos bugs en runtime
   - **Contras:** Curva de aprendizaje, tiempo de migraciÃ³n alto, equipo sin experiencia, compilaciÃ³n adicional
   - **Por quÃ© se rechazÃ³:** Costo de migraciÃ³n muy alto para proyecto ya funcional

2. **TypeScript solo en cÃ³digo nuevo**
   - **Pros:** AdopciÃ³n gradual, menor riesgo
   - **Contras:** Codebase mixto (confuso), tooling mÃ¡s complejo
   - **Por quÃ© se rechazÃ³:** Complejidad de mantener 2 estilos

3. **JSDoc con type annotations**
   - **Pros:** Type hints sin compilaciÃ³n, compatible con JavaScript
   - **Contras:** Menos potente que TypeScript, verboso
   - **Por quÃ© se rechazÃ³:** No implementado, equipo no lo usa

### Consecuencias

**Positivas:**

- âœ… No requiere compilaciÃ³n (desarrollo mÃ¡s rÃ¡pido)

- âœ… Curva de aprendizaje menor (equipo ya conoce JavaScript)

- âœ… Ecosystem de Node.js completo sin fricciÃ³n

**Negativas (Trade-offs aceptados):**

- âŒ Bugs de tipos en runtime (ej: `undefined is not a function`)

- âŒ Refactoring mÃ¡s peligroso (sin type safety)

- âŒ Autocompletado IDE limitado

- âŒ DocumentaciÃ³n de tipos manual (comentarios)

**Riesgos y mitigaciones:**

- **Riesgo:** Bugs de tipos en producciÃ³n
  - **MitigaciÃ³n:** Testing manual exhaustivo (segÃºn respuestas: `testing_strategy: manual`)

- **Riesgo:** Refactoring genera regresiones
  - **MitigaciÃ³n:** Code reviews, testing pre-deploy

### Estado de Testing

SegÃºn respuestas del formulario: `testing_strategy: ['manual', 'none']`

**RecomendaciÃ³n:** Sin TypeScript, testing automatizado es CRÃTICO. Priorizar:

- Unit tests (Jest) para Logic Layer

- Integration tests (Supertest) para API

- E2E tests (Cypress) para flujos crÃ­ticos

### Referencias

- Respuesta formulario: `why_no_typescript: "AplicaciÃ³n heredada con esas caracterÃ­sticas"`

---

## ADR-009: PM2 como Orquestador (Deprecado)

### Estado
**Obsoleta** â†’ **Se eliminarÃ¡**

### Contexto

El sistema necesitaba gestiÃ³n de procesos Node.js:

- Auto-restart si el proceso falla

- Load balancing (cluster mode)

- Logs centralizados

- Monitoring bÃ¡sico

### DecisiÃ³n (Heredada)

Usar **PM2** como orquestador de procesos (configurado en `ecosystem.config.js`).

### Problema Identificado

**Del formulario (`why_pm2`):**
> *"PM2 estÃ¡ en desuso, se puede eliminar"*

**Razones para eliminar:**

- âš ï¸ No se usa realmente (1 instancia en producciÃ³n)

- âš ï¸ Overhead innecesario

- âš ï¸ Herramienta redundante si se migra a Kubernetes o Docker Swarm

### Alternativas para Reemplazo

1. **Kubernetes**
   - **Pros:** OrquestaciÃ³n enterprise, auto-scaling, self-healing, multi-cloud
   - **Contras:** Complejidad alta, overhead operacional, requiere expertise
   - **Estado:** No confirmado en respuestas

2. **Docker Swarm**
   - **Pros:** MÃ¡s simple que Kubernetes, integrado en Docker
   - **Contras:** Menos features, comunidad menor
   - **Estado:** No confirmado en respuestas

3. **Systemd (Linux)**
   - **Pros:** Nativo en Linux, simple, auto-restart
   - **Contras:** No tiene clustering ni load balancing
   - **Estado:** OpciÃ³n ligera para instancia Ãºnica

4. **Sin orquestador (solo Docker)**
   - **Pros:** Simplicidad mÃ¡xima
   - **Contras:** Sin auto-restart automÃ¡tico (depende de Docker restart policy)
   - **Estado:** Suficiente para desarrollo

### Plan

**Eliminar PM2** y decidir orquestador definitivo basado en estrategia de escalado:

- Si se queda en 1 instancia: Systemd o Docker restart policy

- Si escala horizontalmente: Kubernetes o Docker Swarm

### Referencias

- ConfiguraciÃ³n: `ecosystem.config.js`

- Respuesta formulario: `why_pm2: "PM2 estÃ¡ en desuso se puede eliminar"`

---

## ADR-010: Cache TTL: Watson 1h, Usuarios 15min, Salas 5min

### Estado
**Aceptada**

### Contexto

Con la implementaciÃ³n de Redis cache (ADR-005), se necesitaba definir TTLs (Time To Live) para cada tipo de dato cacheado.

**Criterios:**

- Balance entre performance (TTL largo) y freshness (TTL corto)

- Frecuencia de cambio de cada tipo de dato

- Impacto de datos stale en experiencia de usuario

### DecisiÃ³n

Configurar TTLs diferenciados por tipo de dato:

| Tipo de Dato | TTL | RazÃ³n |
|--------------|-----|-------|
| **Watson Session IDs** | **1 hora (3600s)** | Sesiones estables durante conversaciÃ³n activa |
| **Usuarios** | **15 minutos (900s)** | Datos de perfil cambian poco frecuentemente |
| **Salas Activas** | **5 minutos (300s)** | Estado de salas es muy dinÃ¡mico |

### JustificaciÃ³n (del formulario - campo vacÃ­o)

El formulario no especificÃ³ razones, se infiere del comportamiento de los datos:

**Watson Session IDs (1h):**

- âœ… Sesiones Watson duran tÃ­picamente <1h (timeout de Watson)

- âœ… No hay problema si session ID en cache expira (se crea nueva automÃ¡ticamente)

- âœ… Reduce drÃ¡sticamente calls a Watson API (80-200ms ganados)

**Usuarios (15min):**

- âœ… Datos de perfil (nombre, email, rol) cambian poco

- âœ… 15min es aceptable para propagaciÃ³n de cambios (ej: cambio de rol)

- âš ï¸ Si se actualiza rol, tarda hasta 15min en reflejarse (aceptable)

**Salas Activas (5min):**

- âœ… Estado de salas cambia constantemente (nuevos mensajes, transferencias, cierres)

- âš ï¸ TTL muy largo causarÃ­a datos stale (agente ve sala como activa cuando ya cerrÃ³)

- âœ… 5min es balance entre performance y freshness

### Alternativas Consideradas

1. **TTL Ãºnico para todos (ej: 10min)**
   - **Pros:** Simplicidad
   - **Contras:** SubÃ³ptimo para cada tipo de dato
   - **Por quÃ© se rechazÃ³:** Diferentes datos tienen diferentes caracterÃ­sticas

2. **TTL muy cortos (ej: 1min)**
   - **Pros:** Datos siempre frescos
   - **Contras:** Hit rate bajo, poco beneficio de cache
   - **Por quÃ© se rechazÃ³:** Desperdicia potencial de cache

3. **TTL muy largos (ej: 1 dÃ­a)**
   - **Pros:** Hit rate altÃ­simo, mÃ¡xima performance
   - **Contras:** Datos muy stale, bugs difÃ­ciles de detectar
   - **Por quÃ© se rechazÃ³:** Experiencia de usuario degradada

### Consecuencias

**Positivas:**

- âœ… Balance Ã³ptimo entre performance y freshness

- âœ… Hit rates altos donde importa (Watson sessions)

- âœ… Datos razonablemente actualizados

**Negativas (Trade-offs aceptados):**

- âš ï¸ Eventual consistency: cambios tardan hasta TTL en propagarse

- âš ï¸ Posibles bugs sutiles si no se invalida cache manualmente en cambios crÃ­ticos

**Riesgos y mitigaciones:**

- **Riesgo:** Cambio crÃ­tico (ej: desactivar agente) tarda 15min en cache
  - **MitigaciÃ³n:** InvalidaciÃ³n manual de cache en operaciones crÃ­ticas

### Referencias

- ConfiguraciÃ³n: `app/services/cache.js`

- DocumentaciÃ³n: `CACHE_IMPLEMENTATION.md`

- Respuesta formulario: `cache_ttl_reasoning: "No sÃ©"` (campo sin especificar)

---

## ADR-011: Axede como Proveedor WhatsApp Business API

### Estado
**Aceptada**

### Contexto

El sistema necesitaba integraciÃ³n con WhatsApp Business API para:

- Enviar y recibir mensajes de texto

- Enviar mensajes multimedia (imÃ¡genes, documentos, audios)

- Recibir webhooks de eventos (nuevos mensajes, estados de entrega)

- Gestionar sesiones de conversaciÃ³n

**RestricciÃ³n:** WhatsApp Business API requiere proveedor oficial (no se puede acceder directo).

### DecisiÃ³n

Usar **Axede** como proveedor oficial de WhatsApp Business API.

### Alternativas Consideradas

1. **Twilio**
   - **Pros:** LÃ­der del mercado, mejor documentaciÃ³n, SDK maduro, features adicionales (Autopilot, Studio)
   - **Contras:** Pricing mÃ¡s alto, vendor lock-in
   - **Por quÃ© se rechazÃ³:** No especificado en respuestas, posiblemente costo o contrato existente

**Del formulario (`alternatives_considered`):** *"Twilio"*

2. **MessageBird**
   - **Pros:** Multi-canal (WhatsApp, SMS, Voice), pricing competitivo
   - **Contras:** Menos features que Twilio
   - **Por quÃ© se rechazÃ³:** No especificado

3. **360Dialog**
   - **Pros:** Especializado en WhatsApp, buen pricing
   - **Contras:** Menos conocido
   - **Por quÃ© se rechazÃ³:** No especificado

### Consecuencias

**Positivas:**

- âœ… IntegraciÃ³n funcional con WhatsApp Business API

- âœ… Webhooks confiables para recepciÃ³n de mensajes

- âœ… Soporte para multimedia

**Negativas (Trade-offs aceptados):**

- âŒ Vendor lock-in a Axede

- âŒ MigraciÃ³n a otro proveedor requiere reescribir integraciÃ³n

- âŒ Dependencia crÃ­tica: si Axede falla, todo el canal WhatsApp cae

**Riesgos y mitigaciones:**

- **Riesgo:** Axede API no disponible
  - **MitigaciÃ³n:** No detectado en cÃ³digo (sin circuit breaker ni fallback)

- **Riesgo:** Cambios en API de Axede rompen integraciÃ³n
  - **MitigaciÃ³n:** Versionado de API (asumido), testing pre-deploy

### MÃ©tricas

- **Criticidad:** ğŸ”´ CrÃ­tica (sin Axede, no hay comunicaciÃ³n con usuarios finales)

- **SLA:** No especificado en respuestas

- **Failover:** No detectado en cÃ³digo

### Referencias

- IntegraciÃ³n: `app/services/axedeapi.js`

- Webhook handler: `app/controllers/whatsappController.js` (579 lÃ­neas)

- LÃ³gica: `app/logic/ExternalRoom.js`

---

## ADR-012: Dividir Backend en 2 Servicios (API vs Cron)

### Estado
**Planificada** â†’ **Q1 2026**

### Contexto

El monolito actual tiene problemas de escalabilidad:

- Socket.IO sin Redis Adapter impide mÃºltiples instancias (ADR-006)

- Cron jobs con race conditions al escalar (ADR-007)

- Necesidad de escalar horizontalmente confirmada (del formulario: `horizontal_scaling_plan: si`)

### DecisiÃ³n

**Dividir el backend en 2 servicios independientes:**

#### Servicio 1: API + WebSockets (MÃºltiples Instancias)
**Responsabilidades:**

- Controllers (18 archivos)

- Logic Layer (26 clases)

- Services (7 + watson/)

- Middlewares (7 archivos)

- Socket.IO con **Redis Adapter**

**CaracterÃ­sticas:**

- âœ… Stateless (puede escalar horizontalmente)

- âœ… Load balancer delante (NGINX, HAProxy, etc.)

- âœ… Auto-scaling basado en CPU/memoria

- âœ… Redis Adapter para Socket.IO (eventos compartidos)

#### Servicio 2: Cron Jobs (Instancia Ãšnica)
**Responsabilidades:**

- `queue.js` (asignaciÃ³n auto cada 30s)

- `rooms.js` (cierre auto, encuestas)

- `room_files.js` (limpieza archivos 23:30)

- `report.js` (reportes 23:45)

**CaracterÃ­sticas:**

- âœ… Solo 1 instancia (cero race conditions)

- âœ… Comparte DB con Servicio 1

- âœ… Puede invocar API del Servicio 1 si necesario

### Plan de ImplementaciÃ³n (Q1 2026)

**Del formulario (`cron_solution`):**
> *"Se dividirÃ¡ el back en dos servicios dejando los crons job en un servicio que solo tendrÃ¡ una instancia, mÃ¡s adelante se migrarÃ¡ a Kafka con IBM, eso estÃ¡ para una segunda fase en el mismo Q1 2026"*

**Fase 1 (Q1 2026):**

1. Desplegar Redis en producciÃ³n

2. Implementar Redis Adapter en Socket.IO

3. Extraer cron jobs a servicio separado

4. Configurar deployment de 2 servicios

5. Testing con mÃºltiples instancias del Servicio 1

6. Deploy gradual (canary)

**Fase 2 (Q1 2026 - posterior):**

7. MigraciÃ³n a **Kafka con IBM** para event-driven architecture

8. Desacoplamiento total entre servicios

9. Escalabilidad horizontal completa

### Arquitectura Futura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Load Balancer (NGINX/HAProxy)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                   â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Servicio 1â”‚       â”‚Servicio 1â”‚  ...  â”‚Servicio 1â”‚
â”‚Instancia â”‚       â”‚Instancia â”‚       â”‚Instancia â”‚
â”‚    #1    â”‚       â”‚    #2    â”‚       â”‚    #N    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                   â”‚                   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Redis Adapter â”‚
         â”‚  (Socket.IO)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  PostgreSQL   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–²
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Servicio 2   â”‚
         â”‚  (Cron Jobs)  â”‚
         â”‚  1 instancia  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Consecuencias

**Positivas:**

- âœ… Escalado horizontal completo del API

- âœ… Cero race conditions en cron jobs

- âœ… Fault isolation (fallo de cron no afecta API)

- âœ… Deployments independientes (API vs Cron)

- âœ… OptimizaciÃ³n de recursos (escalar solo lo necesario)

**Negativas (Trade-offs aceptados):**

- âŒ Complejidad operacional aumenta (2 servicios vs 1)

- âŒ Deployment mÃ¡s complejo (orquestar 2 servicios)

- âŒ Debugging distribuido (logs en mÃºltiples lugares)

- âŒ Requiere Redis en producciÃ³n (componente adicional)

**Riesgos y mitigaciones:**

- **Riesgo:** Complejidad de deployment
  - **MitigaciÃ³n:** Docker Compose o Kubernetes (orquestaciÃ³n automÃ¡tica)

- **Riesgo:** Redis SPOF (Single Point of Failure)
  - **MitigaciÃ³n:** Redis Sentinel o ElastiCache (HA)

- **Riesgo:** Logs distribuidos dificultan debugging
  - **MitigaciÃ³n:** Centralizar logs (ELK Stack, Grafana Loki)

### PrÃ³ximos Pasos

1. âœ… Documentar arquitectura actual (este documento)

2. â³ Desplegar Redis en producciÃ³n (Q1 2026)

3. â³ Implementar Redis Adapter (Q1 2026)

4. â³ Extraer cron jobs a servicio separado (Q1 2026)

5. â³ MigraciÃ³n a Kafka con IBM (Fase 2, Q1 2026)

### Referencias

- Plan: Respuesta formulario `cron_solution`

- Problemas actuales: ADR-006, ADR-007

- Escalado horizontal: Respuesta `horizontal_scaling_plan: si`

---

## ğŸ“Š Resumen de Decisiones

### Decisiones Vigentes (Aceptadas)

| ADR | DecisiÃ³n | Impacto | RevisiÃ³n Futura |
|-----|----------|---------|-----------------|
| ADR-001 | PostgreSQL | Alto | No planificada |
| ADR-002 | IBM Watson Assistant | Alto | En evaluaciÃ³n |
| ADR-003 | Monolito Modular | Alto | Q1 2026 (divisiÃ³n en 2) |
| ADR-004 | IBM Cloud Object Storage | Medio | No planificada |
| ADR-005 | Redis Cache con Fallback | Medio | ProducciÃ³n Q1 2026 |
| ADR-008 | JavaScript (sin TypeScript) | Medio | No planificada |
| ADR-010 | Cache TTLs diferenciados | Bajo | Ajuste segÃºn mÃ©tricas |
| ADR-011 | Axede WhatsApp API | Alto | No planificada |

### Decisiones Temporales (En RevisiÃ³n)

| ADR | DecisiÃ³n | Problema | ResoluciÃ³n |
|-----|----------|----------|------------|
| ADR-006 | Socket.IO sin Redis Adapter | No escalable | Q1 2026 |
| ADR-007 | Cron jobs con flags | Race conditions | Q1 2026 |

### Decisiones Obsoletas (Deprecadas)

| ADR | DecisiÃ³n | RazÃ³n | Reemplazo |
|-----|----------|-------|-----------|
| ADR-009 | PM2 como orquestador | En desuso | Por definir (K8s/Swarm/Systemd) |

### Decisiones Futuras (Planificadas)

| ADR | DecisiÃ³n | Timeline | Impacto |
|-----|----------|----------|---------|
| ADR-012 | Dividir backend en 2 servicios | Q1 2026 | Alto |
| - | MigraciÃ³n a Kafka con IBM | Q1 2026 (Fase 2) | Alto |
| - | EvaluaciÃ³n migraciÃ³n Watson | TBD | Alto |

---

## ğŸ”„ Proceso de ADR

### CuÃ¡ndo crear un ADR

- Decisiones arquitectÃ³nicas que impactan mÃºltiples componentes

- Trade-offs significativos entre alternativas

- Cambios difÃ­ciles de revertir (ej: elecciÃ³n de DB, framework)

- Restricciones de negocio o tÃ©cnicas importantes

### Plantilla de ADR

```markdown
## ADR-XXX: [TÃ­tulo]

### Estado
[Propuesta / Aceptada / Rechazada / Obsoleta / En revisiÃ³n]

### Contexto
[Problema a resolver, restricciones]

### DecisiÃ³n
[QuÃ© se decidiÃ³ hacer]

### Alternativas Consideradas

1. **[Alternativa 1]**
   - Pros: [...]
   - Contras: [...]
   - Por quÃ© se rechazÃ³: [...]

### Consecuencias
**Positivas:** [Beneficios]
**Negativas (Trade-offs):** [Compromisos aceptados]
**Riesgos:** [Riesgos y mitigaciones]

### Referencias
[Links a cÃ³digo, docs, tickets]
```

---

## ğŸ“š Referencias Externas

- [Architecture Decision Records (ADR) - GitHub](https://adr.github.io/)

- [Documenting Architecture Decisions - Michael Nygard](https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions)

- [ADR Tools](https://github.com/npryce/adr-tools)

---
